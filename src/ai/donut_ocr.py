# Generated by Copilot
from typing import Dict, List, Optional, Any
import torch
from transformers import DonutProcessor, VisionEncoderDecoderModel
from PIL import Image
import json
import os
from datetime import datetime
import requests
import base64
import io

from ..utils.config import Config
from ..utils.logger import Logger
from ..models.document import Document, ExtractedField, ProcessingResult

class DonutOCREngine:
    """
    HuggingFace Donut Transformer for document understanding and OCR
    Phase 2 implementation - Free alternative to paid OCR APIs
    """
    
    def __init__(self):
        self.logger = Logger(__name__)
        self.config = Config()
        
        # Model configurations for different document types
        self.model_configs = {
            'cv_resume': {
                'model_name': "naver-clova-ix/donut-base-finetuned-cord-v2",
                'max_length': 768,
                'task_prompt': "<s_cord-v2>"
            },
            'invoice_receipt': {
                'model_name': "naver-clova-ix/donut-base-finetuned-rvlcdip", 
                'max_length': 512,
                'task_prompt': "<s_rvlcdip>"
            },
            'general_document': {
                'model_name': "naver-clova-ix/donut-base",
                'max_length': 1024,
                'task_prompt': "<s>"
            }
        }
        
        # Initialize models lazily
        self.processors = {}
        self.models = {}
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        self.logger.info(f"DonutOCR initialized with device: {self.device}")
    
    def _load_model(self, document_type: str = 'general_document'):
        """Load Donut model and processor for specific document type"""
        if document_type in self.models:
            return self.processors[document_type], self.models[document_type]
        
        try:
            config = self.model_configs.get(document_type, self.model_configs['general_document'])
            model_name = config['model_name']
            
            self.logger.info(f"Loading Donut model: {model_name}")
            
            # Load processor and model
            processor = DonutProcessor.from_pretrained(
                model_name,
                use_auth_token=self.config.HUGGINGFACE_TOKEN
            )
            model = VisionEncoderDecoderModel.from_pretrained(
                model_name,
                use_auth_token=self.config.HUGGINGFACE_TOKEN
            )
            
            # Move to device
            model.to(self.device)
            model.eval()
            
            # Cache loaded models
            self.processors[document_type] = processor
            self.models[document_type] = model
            
            self.logger.info(f"Successfully loaded Donut model: {model_name}")
            return processor, model
            
        except Exception as e:
            self.logger.error(f"Error loading Donut model {model_name}: {e}")
            raise
    
    def extract_data_from_image(self, image_path: str, document_type: str = 'general_document') -> Dict[str, Any]:
        """
        Extract structured data from document image using Donut transformer
        """
        try:
            self.logger.info(f"Processing image with Donut: {image_path}")
            
            # Load appropriate model
            processor, model = self._load_model(document_type)
            
            # Load and preprocess image
            image = Image.open(image_path)
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # Get model configuration
            config = self.model_configs[document_type]
            task_prompt = config['task_prompt']
            max_length = config['max_length']
            
            # Prepare inputs
            pixel_values = processor(image, return_tensors="pt").pixel_values
            pixel_values = pixel_values.to(self.device)
            
            # Prepare decoder input
            decoder_input_ids = processor.tokenizer(
                task_prompt, 
                add_special_tokens=False, 
                return_tensors="pt"
            ).input_ids
            decoder_input_ids = decoder_input_ids.to(self.device)
            
            # Generate predictions
            with torch.no_grad():
                outputs = model.generate(
                    pixel_values,
                    decoder_input_ids=decoder_input_ids,
                    max_length=max_length,
                    early_stopping=True,
                    pad_token_id=processor.tokenizer.pad_token_id,
                    eos_token_id=processor.tokenizer.eos_token_id,
                    use_cache=True,
                    num_beams=1,
                    bad_words_ids=[[processor.tokenizer.unk_token_id]],
                    return_dict_in_generate=True,
                )
            
            # Decode predictions
            sequence = processor.batch_decode(outputs.sequences)[0]
            sequence = sequence.replace(processor.tokenizer.eos_token, "").replace(processor.tokenizer.pad_token, "")
            sequence = sequence.replace(task_prompt, "")
            
            # Parse structured output based on document type
            extracted_data = self._parse_donut_output(sequence, document_type)
            
            self.logger.info(f"Successfully extracted data from {image_path}")
            return {
                'success': True,
                'extracted_data': extracted_data,
                'raw_output': sequence,
                'confidence': self._calculate_confidence(extracted_data),
                'processing_time': 0.0,  # Add timing if needed
                'model_used': config['model_name']
            }
            
        except Exception as e:
            self.logger.error(f"Error processing image with Donut: {e}")
            return {
                'success': False,
                'error': str(e),
                'extracted_data': {},
                'confidence': 0.0
            }
    
    def _parse_donut_output(self, sequence: str, document_type: str) -> Dict[str, ExtractedField]:
        """
        Parse Donut model output into structured data based on document type
        """
        extracted_data = {}
        
        try:
            if document_type == 'cv_resume':
                extracted_data = self._parse_cv_data(sequence)
            elif document_type == 'invoice_receipt':
                extracted_data = self._parse_invoice_data(sequence)
            else:
                extracted_data = self._parse_general_document(sequence)
                
        except Exception as e:
            self.logger.warning(f"Error parsing Donut output: {e}")
            # Fallback to text extraction
            extracted_data = {
                'text_content': ExtractedField(sequence, 70.0)
            }
        
        return extracted_data
    
    def _parse_cv_data(self, sequence: str) -> Dict[str, ExtractedField]:
        """Parse CV/Resume specific data from Donut output"""
        extracted_data = {}
        
        try:
            # Try to parse as JSON first
            if sequence.strip().startswith('{'):
                data = json.loads(sequence)
                
                # Extract common CV fields
                fields_mapping = {
                    'name': ['name', 'full_name', 'candidate_name'],
                    'email': ['email', 'email_address', 'contact_email'],
                    'phone': ['phone', 'mobile', 'contact_number', 'phone_number'],
                    'address': ['address', 'location', 'residence'],
                    'experience': ['experience', 'work_experience', 'employment'],
                    'education': ['education', 'qualifications', 'academic'],
                    'skills': ['skills', 'competencies', 'expertise']
                }
                
                for field, possible_keys in fields_mapping.items():
                    for key in possible_keys:
                        if key in data:
                            confidence = 85.0 if isinstance(data[key], str) and len(data[key]) > 3 else 60.0
                            extracted_data[field] = ExtractedField(str(data[key]), confidence)
                            break
            
        except json.JSONDecodeError:
            # Fallback to regex/text parsing
            import re
            
            # Simple pattern matching for CV data
            patterns = {
                'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
                'phone': r'[\+]?[1-9]?[0-9]{7,15}',
                'name': r'^[A-Z][a-z]+ [A-Z][a-z]+',  # Simple name pattern
            }
            
            for field, pattern in patterns.items():
                matches = re.findall(pattern, sequence, re.MULTILINE)
                if matches:
                    extracted_data[field] = ExtractedField(matches[0], 75.0)
        
        # Always include raw text
        extracted_data['raw_text'] = ExtractedField(sequence, 90.0)
        
        return extracted_data
    
    def _parse_invoice_data(self, sequence: str) -> Dict[str, ExtractedField]:
        """Parse invoice/receipt specific data"""
        extracted_data = {}
        
        try:
            if sequence.strip().startswith('{'):
                data = json.loads(sequence)
                
                # Invoice-specific fields
                invoice_fields = {
                    'invoice_number': ['invoice_number', 'invoice_id', 'receipt_number'],
                    'date': ['date', 'invoice_date', 'issue_date'],
                    'total_amount': ['total', 'amount', 'total_amount', 'grand_total'],
                    'vendor': ['vendor', 'company', 'supplier', 'merchant']
                }
                
                for field, possible_keys in invoice_fields.items():
                    for key in possible_keys:
                        if key in data:
                            extracted_data[field] = ExtractedField(str(data[key]), 80.0)
                            break
                            
        except json.JSONDecodeError:
            # Text-based extraction for invoices
            import re
            
            # Invoice patterns
            amount_pattern = r'[\$£€]?[\d,]+\.?\d{0,2}'
            date_pattern = r'\d{1,2}[/-]\d{1,2}[/-]\d{2,4}'
            
            amounts = re.findall(amount_pattern, sequence)
            dates = re.findall(date_pattern, sequence)
            
            if amounts:
                extracted_data['total_amount'] = ExtractedField(amounts[-1], 70.0)  # Last amount often total
            if dates:
                extracted_data['date'] = ExtractedField(dates[0], 75.0)
        
        extracted_data['raw_text'] = ExtractedField(sequence, 90.0)
        return extracted_data
    
    def _parse_general_document(self, sequence: str) -> Dict[str, ExtractedField]:
        """Parse general document text"""
        return {
            'text_content': ExtractedField(sequence, 85.0),
            'word_count': ExtractedField(str(len(sequence.split())), 95.0),
            'character_count': ExtractedField(str(len(sequence)), 95.0)
        }
    
    def _calculate_confidence(self, extracted_data: Dict[str, ExtractedField]) -> float:
        """Calculate overall confidence score for extraction"""
        if not extracted_data:
            return 0.0
        
        confidences = [field.confidence for field in extracted_data.values()]
        return sum(confidences) / len(confidences)
    
    def process_document(self, document: Document) -> Document:
        """
        Main entry point for processing a document with Donut OCR
        """
        try:
            self.logger.info(f"Starting Donut OCR processing for document: {document.id}")
            
            # Get document type for model selection
            doc_type = self._map_document_type(document.document_type)
            
            # Process each image/page
            all_extracted_data = {}
            total_confidence = 0.0
            processed_pages = 0
            
            # Get image paths (from file handler conversion)
            image_paths = self._get_image_paths(document)
            
            if not image_paths:
                raise ValueError("No images found for document processing")
            
            for i, image_path in enumerate(image_paths):
                self.logger.info(f"Processing page {i+1}/{len(image_paths)}")
                
                # Extract data from this page
                page_result = self.extract_data_from_image(image_path, doc_type)
                
                if page_result['success']:
                    # Merge page data with prefix
                    for field_name, field_data in page_result['extracted_data'].items():
                        key = f"page_{i+1}_{field_name}" if len(image_paths) > 1 else field_name
                        all_extracted_data[key] = field_data
                    
                    total_confidence += page_result['confidence']
                    processed_pages += 1
                else:
                    self.logger.warning(f"Failed to process page {i+1}: {page_result.get('error', 'Unknown error')}")
            
            # Calculate overall confidence
            overall_confidence = total_confidence / max(processed_pages, 1)
            
            # Create processing result
            processing_result = ProcessingResult(
                success=True,
                extracted_data=all_extracted_data,
                confidence=overall_confidence,
                processing_cost=0.0,  # Donut is free!
                classification=document.document_type,
                ocr_engine="donut_transformer",
                processing_time=0.0,  # Add timing if needed
                pages_processed=processed_pages
            )
            
            # Update document
            document.processing_results.append(processing_result)
            document.extracted_data = all_extracted_data
            document.processing_cost = 0.0  # Free processing!
            
            # Add processing step
            document.add_processing_step('donut_ocr_extraction', {
                'model_type': doc_type,
                'pages_processed': processed_pages,
                'overall_confidence': overall_confidence,
                'timestamp': datetime.now().isoformat()
            })
            
            self.logger.info(f"Donut OCR processing completed for document: {document.id}")
            return document
            
        except Exception as e:
            self.logger.error(f"Error in Donut OCR processing: {e}")
            document.add_processing_step('donut_ocr_error', {
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            })
            raise
    
    def _map_document_type(self, document_type) -> str:
        """Map document type to Donut model type"""
        if hasattr(document_type, 'value'):
            doc_type = document_type.value.lower()
        else:
            doc_type = str(document_type).lower()
        
        if 'cv' in doc_type or 'resume' in doc_type:
            return 'cv_resume'
        elif 'invoice' in doc_type or 'receipt' in doc_type:
            return 'invoice_receipt'
        else:
            return 'general_document'
    
    def _get_image_paths(self, document: Document) -> List[str]:
        """Get image paths for document processing"""
        # This should integrate with your existing file handler
        # For now, assume images are stored in a predictable location
        image_dir = os.path.join(self.config.TEMP_FOLDER, document.id)
        
        if os.path.exists(image_dir):
            image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            return [os.path.join(image_dir, f) for f in sorted(image_files)]
        
        # Fallback to original file if it's an image
        if document.file_path and document.file_path.lower().endswith(('.png', '.jpg', '.jpeg')):
            return [document.file_path]
        
        return []
    
    def get_supported_document_types(self) -> List[str]:
        """Get list of supported document types for Donut processing"""
        return list(self.model_configs.keys())
    
    def cleanup_models(self):
        """Free up GPU memory by clearing loaded models"""
        for model in self.models.values():
            if hasattr(model, 'cpu'):
                model.cpu()
        
        self.models.clear()
        self.processors.clear()
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        self.logger.info("Donut models cleaned up from memory")
